{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"SOMA Curation Documentation","text":"<p>Welcome to the SOMA Curation documentation! This package provides tools for managing and curating single-cell RNA sequencing data using the TileDB-SOMA framework.</p>"},{"location":"#getting-started","title":"Getting Started","text":"<ul> <li>Installation</li> <li>Quick Start Guide</li> <li>Basic Concepts</li> <li>Releases &amp; Versioning</li> </ul>"},{"location":"#usage","title":"Usage","text":"<ul> <li>Basic Usage</li> <li>Data Organization</li> </ul>"},{"location":"#advanced","title":"Advanced","text":"<ul> <li>Multiprocessing Ingestion</li> </ul>"},{"location":"#api-reference","title":"API Reference","text":"<ul> <li>Atlas</li> <li>Dataset</li> </ul>"},{"location":"#documentation-source","title":"Documentation Source","text":"<p>This documentation is built using MkDocs with the Material for MkDocs theme. The documentation is automatically built and deployed when changes are pushed to the main branch.</p>"},{"location":"advanced/multiprocessing/","title":"Multiprocessing Ingestion","text":"<p>SOMA Curation supports parallel processing for efficient data ingestion. This is especially useful when working with large datasets that contain many samples.</p>"},{"location":"advanced/multiprocessing/#command-line-interface","title":"Command-Line Interface","text":"<p>The simplest way to use multiprocessing is through the command-line interface:</p> <pre><code>python -m soma_curation.scripts.multiprocessing_ingest \\\n    --processes 4 \\\n    --atlas-name my_atlas \\\n    --raw-storage-dir path/to/raw_data \\\n    --h5ad-storage-dir path/to/h5ads \\\n    --atlas-storage-dir path/to/atlas \\\n    --log-dir path/to/logs\n</code></pre>"},{"location":"advanced/multiprocessing/#key-parameters","title":"Key Parameters","text":"<ul> <li><code>--processes</code>: Number of worker processes to use (default: 4)</li> <li><code>--atlas-name</code>: Name of the atlas to create or update</li> <li><code>--raw-storage-dir</code>: Directory containing raw data</li> <li><code>--h5ad-storage-dir</code>: Directory for temporary H5AD file storage</li> <li><code>--atlas-storage-dir</code>: Directory for atlas storage</li> <li><code>--log-dir</code>: Directory for logs</li> <li><code>--db-schema-fp</code>: Optional path to custom schema file</li> <li><code>--filenames-pkl</code>: Path to store/load successful H5AD filenames</li> <li><code>--registration-mapping-pkl</code>: Path to store/load registration mapping</li> </ul>"},{"location":"advanced/multiprocessing/#pipeline-steps","title":"Pipeline Steps","text":"<p>The multiprocessing ingestion pipeline consists of four main steps:</p> <ol> <li>Convert to H5AD: Convert each study-sample pair to H5AD format in parallel</li> <li>Create Registration Mapping: Map each sample to its position in the atlas (serial step)</li> <li>Resize Experiment: Allocate space in the atlas (serial step)</li> <li>Ingest H5AD: Load H5AD files into the atlas in parallel</li> </ol>"},{"location":"advanced/multiprocessing/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Process Count: Set <code>--processes</code> to match your CPU cores (or slightly less)</li> <li>Memory Usage: Each process requires memory for loading a sample</li> <li>Storage Space: Ensure sufficient space for both raw data and H5AD files</li> <li>Checkpointing: Use the pickle files to resume interrupted ingestion</li> </ul>"},{"location":"advanced/multiprocessing/#error-handling","title":"Error Handling","text":"<p>The pipeline logs failures but continues processing other samples. You can check:</p> <ul> <li>The log files for detailed error information</li> <li>The success/failure counts in the command output</li> <li>Failed samples by comparing input data with successfully processed files</li> </ul>"},{"location":"advanced/multiprocessing/#example-workflow","title":"Example Workflow","text":"<ol> <li>Organize your data following the Data Organization guidelines</li> <li>Run the multiprocessing ingestion script</li> <li>Check logs for any errors or warnings</li> <li>Access your data using the AtlasManager</li> </ol> <pre><code>from soma_curation.atlas.crud import AtlasManager\nfrom soma_curation.schema import load_schema\n\n# Load the completed atlas\nam = AtlasManager(\n    atlas_name=\"my_atlas\",\n    storage_directory=\"path/to/atlas\",\n    db_schema=load_schema()\n)\n\n# Access the atlas data\nwith am.open(mode=\"r\") as exp:\n    # Work with the experiment data\n    print(exp.ms.keys())\n</code></pre>"},{"location":"api_reference/atlas/","title":"Atlas","text":"<p>handler: python options: show_root_heading: true show_source: true</p>"},{"location":"api_reference/atlas/#soma_curation.atlas.crud.AtlasManager","title":"<code>soma_curation.atlas.crud.AtlasManager</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>AtlasManager class is designed to manage the creation, deletion, and schema management for single-cell RNA sequencing atlases.</p> <ul> <li>atlas_name: str     The name of the atlas.</li> <li>db_schema: DatabaseSchema     The schema defining the structure and validation rules for the data.</li> <li>storage_directory: Path     The directory where the atlas is stored.</li> <li>context: soma.SOMATileDBContext     The context for TileDB-SOMA operations, with a default factory function.</li> </ul> <p>Methods: - exists: Checks if the atlas already exists. - create: Creates a new atlas. - delete: Deletes an existing atlas.</p>"},{"location":"api_reference/atlas/#soma_curation.atlas.crud.AtlasManager.experiment_path","title":"<code>experiment_path</code>  <code>property</code>","text":"<p>Compute the path to the experiment directory.</p> <ul> <li>Path     The path to the experiment directory.</li> </ul>"},{"location":"api_reference/atlas/#soma_curation.atlas.crud.AtlasManager.version","title":"<code>version</code>  <code>property</code>","text":"<p>Compute the version</p> <ul> <li>Path     The version</li> </ul>"},{"location":"api_reference/atlas/#soma_curation.atlas.crud.AtlasManager.create","title":"<code>create()</code>","text":"<p>Create a new atlas.</p> <p>This method initializes the experiment directory, sets up metadata, and creates necessary collections and dataframes.</p>"},{"location":"api_reference/atlas/#soma_curation.atlas.crud.AtlasManager.delete","title":"<code>delete()</code>","text":"<p>Delete an existing atlas.</p> <p>This method removes the directory and all its contents.</p>"},{"location":"api_reference/atlas/#soma_curation.atlas.crud.AtlasManager.exists","title":"<code>exists()</code>","text":"<p>Check if the atlas already exists.</p> <ul> <li>bool     True if the atlas exists, False otherwise.</li> </ul>"},{"location":"api_reference/atlas/#soma_curation.atlas.crud.AtlasManager.load_schema_if_missing","title":"<code>load_schema_if_missing(v, info)</code>  <code>classmethod</code>","text":"<p>If no schema is provided and the atlas exists, load the schema from experiment metadata. Otherwise, if the atlas does not exist and no schema is provided, raise an error.</p>"},{"location":"api_reference/dataset/","title":"Dataset","text":"<p>handler: python options: show_root_heading: true show_source: true</p>"},{"location":"api_reference/dataset/#soma_curation.dataset.anndataset.AnnDataset","title":"<code>soma_curation.dataset.anndataset.AnnDataset</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>AnnDataset class is designed to validate and standardize AnnData objects according to a given database schema.</p> <ul> <li>artifact: ad.AnnData     The AnnData object containing the data matrix.</li> <li>db_schema: DatabaseSchema     The schema defining the structure and validation rules for the data.</li> </ul> <p>Methods: - validate: Validates the AnnData object against the provided schema. - standardize: Standardizes the AnnData object by normalizing and computing required columns.</p>"},{"location":"api_reference/dataset/#soma_curation.dataset.anndataset.AnnDataset.standardize","title":"<code>standardize()</code>","text":"<p>Standardize the AnnData object by normalizing and computing required columns.</p> <ul> <li>bool     True if standardization is successful.</li> </ul>"},{"location":"api_reference/dataset/#soma_curation.dataset.anndataset.AnnDataset.validate","title":"<code>validate()</code>","text":"<p>Validate the AnnData object.</p> <ul> <li>Self     The validated AnnDataset object.</li> </ul>"},{"location":"api_reference/dataset/#soma_curation.dataset.anndataset.AnnDataset.write","title":"<code>write(output_filepath)</code>","text":"<p>Write the AnnDataset to H5AD format at a specific filepath</p> <p>Parameters:</p> Name Type Description Default <code>output_filepath</code> <code>Union[str, Path, CloudPath]</code> <p>Needs to end with <code>.h5ad</code></p> required <p>Returns:</p> Type Description <code>Union[Path, CloudPath]</code> <p>Union[Path, CloudPath]: Location of written H5AD object</p>"},{"location":"getting_started/concepts/","title":"Basic Concepts","text":"<p>This guide explains the fundamental concepts and components of SOMA Curation.</p>"},{"location":"getting_started/concepts/#core-components","title":"Core Components","text":""},{"location":"getting_started/concepts/#schema","title":"Schema","text":"<p>The schema defines the structure and validation rules for your data. It includes:</p> <ul> <li>Column definitions for samples and cells</li> <li>Data types and constraints</li> <li>Version information</li> <li>Platform configurations</li> </ul> <p>Example schema components:</p> <pre><code>PAI_OBS_SAMPLE_COLUMNS = [\n    (\"sample_name\", \"string\"),\n    (\"study_name\", \"string\"),\n    # ...\n]\n\nPAI_OBS_CELL_COLUMNS = [\n    (\"barcode\", \"string\"),\n    # ...\n]\n</code></pre>"},{"location":"getting_started/concepts/#collections","title":"Collections","text":"<p>Collections (<code>MtxCollection</code>) manage your raw data:</p> <ul> <li>Organize data by studies and samples</li> <li>Handle both local and cloud storage (S3)</li> <li>Validate data structure and integrity</li> <li>Provide access to metadata and matrices</li> </ul>"},{"location":"getting_started/concepts/#atlas","title":"Atlas","text":"<p>The Atlas (<code>AtlasManager</code>) manages processed data:</p> <ul> <li>Stores data in TileDB-SOMA format</li> <li>Handles versioning and metadata</li> <li>Provides efficient data access</li> <li>Supports parallel processing</li> </ul>"},{"location":"getting_started/concepts/#data-organization","title":"Data Organization","text":""},{"location":"getting_started/concepts/#directory-structure","title":"Directory Structure","text":"<pre><code>raw_data/\n\u251c\u2500\u2500 study_1/\n\u2502   \u251c\u2500\u2500 mtx/              # Matrix files\n\u2502   \u251c\u2500\u2500 cell_metadata/    # Cell-level metadata\n\u2502   \u2514\u2500\u2500 sample_metadata/  # Sample-level metadata\n\u2514\u2500\u2500 study_2/\n    \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"getting_started/concepts/#file-formats","title":"File Formats","text":"<ul> <li>Matrix files: <code>.mtx.gz</code> (Matrix Market format)</li> <li>Metadata files: <code>.tsv.gz</code> (Tab-separated values)</li> <li>Features and barcodes: <code>.tsv.gz</code></li> </ul>"},{"location":"getting_started/concepts/#data-flow","title":"Data Flow","text":"<ol> <li> <p>Raw Data</p> </li> <li> <p>Organized in studies and samples</p> </li> <li>Stored in specified directory structure</li> <li> <p>Validated against schema</p> </li> <li> <p>Collection</p> </li> <li> <p>Manages access to raw data</p> </li> <li>Validates data integrity</li> <li> <p>Provides data access methods</p> </li> <li> <p>Atlas</p> </li> <li>Stores processed data</li> <li>Manages versioning</li> <li>Provides efficient querying</li> </ol>"},{"location":"getting_started/concepts/#key-features","title":"Key Features","text":""},{"location":"getting_started/concepts/#validation","title":"Validation","text":"<ul> <li>Schema compliance</li> <li>Data integrity checks</li> <li>Duplicate detection</li> <li>Format validation</li> </ul>"},{"location":"getting_started/concepts/#flexibility","title":"Flexibility","text":"<ul> <li>Support for local and cloud storage</li> <li>Customizable schema</li> <li>Extensible architecture</li> <li>Parallel processing support</li> </ul>"},{"location":"getting_started/concepts/#integration","title":"Integration","text":"<ul> <li>Compatible with TileDB-SOMA</li> <li>Works with common single-cell tools</li> <li>Supports standard file formats</li> <li>Integrates with existing pipelines</li> </ul>"},{"location":"getting_started/concepts/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Schema Design</p> </li> <li> <p>Define clear column names and types</p> </li> <li>Include necessary metadata</li> <li> <p>Plan for future extensions</p> </li> <li> <p>Data Organization</p> </li> <li> <p>Follow the recommended structure</p> </li> <li>Use consistent naming</li> <li> <p>Maintain clear documentation</p> </li> <li> <p>Processing</p> </li> <li>Validate data early</li> <li>Use appropriate resources</li> <li>Monitor progress</li> <li>Keep logs</li> </ol>"},{"location":"getting_started/concepts/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about Schema Definition</li> <li>Explore Data Organization</li> </ul>"},{"location":"getting_started/installation/","title":"Installation","text":""},{"location":"getting_started/installation/#prerequisites","title":"Prerequisites","text":"<p>Before installing SOMA Curation, ensure you have:</p> <ul> <li>Python 3.8 or higher</li> <li>pip (Python package installer)</li> <li>Virtual environment (recommended)</li> </ul>"},{"location":"getting_started/installation/#installation-methods","title":"Installation Methods","text":""},{"location":"getting_started/installation/#using-pip-stable-release","title":"Using pip (Stable Release)","text":"<p>The simplest way to install the stable release of SOMA Curation is using pip:</p> <pre><code>pip install soma-curation\n</code></pre>"},{"location":"getting_started/installation/#using-testpypi-pre-releases","title":"Using TestPyPI (Pre-releases)","text":"<p>To install pre-release versions for testing:</p> <pre><code># Install from TestPyPI\npip install --index-url https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple soma-curation\n</code></pre> <p>Pre-releases are published when a GitHub release is marked as a pre-release. These versions may contain new features that are still under development or testing.</p>"},{"location":"getting_started/installation/#from-source","title":"From Source","text":"<p>If you want to install from source or contribute to the development:</p> <ol> <li>Clone the repository:</li> </ol> <pre><code>git clone https://github.com/PhenomicAI/soma-curation.git\ncd soma-curation\n</code></pre> <ol> <li>Create and activate a virtual environment:</li> </ol> <pre><code>python -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\n</code></pre> <ol> <li>Install the package in development mode:</li> </ol> <pre><code>pip install -e .\n</code></pre>"},{"location":"getting_started/installation/#dependencies","title":"Dependencies","text":"<p>SOMA Curation has the following main dependencies:</p> <ul> <li>pandas</li> <li>numpy</li> <li>scipy</li> <li>anndata</li> <li>tiledbsoma</li> <li>cloudpathlib</li> <li>pydantic</li> </ul> <p>These will be automatically installed when you install the package.</p>"},{"location":"getting_started/installation/#verifying-installation","title":"Verifying Installation","text":"<p>To verify your installation, you can run:</p> <pre><code>import soma_curation\nprint(soma_curation.__version__)\n</code></pre>"},{"location":"getting_started/installation/#troubleshooting","title":"Troubleshooting","text":"<p>If you encounter any issues during installation:</p> <ol> <li>Ensure you're using a supported Python version</li> <li>Try upgrading pip: <code>pip install --upgrade pip</code></li> <li>Check if all dependencies are properly installed</li> <li>If using a virtual environment, ensure it's activated</li> </ol> <p>For additional help, see the Troubleshooting guide.</p>"},{"location":"getting_started/quickstart/","title":"Quick Start Guide","text":"<p>This guide will help you get started with SOMA Curation quickly. We'll walk through the basic workflow of setting up a schema, organizing data, and creating a collection.</p>"},{"location":"getting_started/quickstart/#1-define-your-schema","title":"1. Define Your Schema","text":"<p>The simplest way to get started is to use the default schema:</p> <pre><code>from soma_curation.schema import load_schema\n\n# loads the default schema\nschema = load_schema()\n</code></pre> <p>For custom schemas, you can create your own:</p> <pre><code>from soma_curation.schema import DatabaseSchema\n\ncustom_schema = DatabaseSchema(\n    PAI_SCHEMA_VERSION=\"1.0\",\n    PAI_OBS_SAMPLE_COLUMNS=[\n        (\"sample_name\", \"string\"),\n        (\"study_name\", \"string\"),\n        # Add more columns as needed\n    ],\n    PAI_OBS_CELL_COLUMNS=[\n        (\"barcode\", \"string\"),\n    ]\n)\n</code></pre>"},{"location":"getting_started/quickstart/#2-organize-your-data","title":"2. Organize Your Data","text":"<p>You can quickly create a test data structure using the provided utility:</p> <pre><code>from soma_curation.utils import test_dummy_structure\ntest_dummy_structure()\n</code></pre> <p>This will create a directory structure like:</p> <pre><code>raw_data/\n\u251c\u2500\u2500 study_1/\n\u2502   \u251c\u2500\u2500 mtx/\n\u2502   \u2502   \u251c\u2500\u2500 sample_1/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 matrix.mtx.gz\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 barcodes.tsv.gz\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 features.tsv.gz\n\u2502   \u2502   \u2514\u2500\u2500 sample_2/\n\u2502   \u251c\u2500\u2500 cell_metadata/\n\u2502   \u2502   \u2514\u2500\u2500 study_1.tsv.gz\n\u2502   \u2514\u2500\u2500 sample_metadata/\n\u2502       \u2514\u2500\u2500 study_1.tsv.gz\n\u2514\u2500\u2500 study_2/\n    \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"getting_started/quickstart/#3-create-a-collection-and-atlas","title":"3. Create a Collection and Atlas","text":"<pre><code>from soma_curation.collection import MtxCollection\nfrom soma_curation.atlas.crud import AtlasManager\n\n# Create a collection to manage raw data\ncollection = MtxCollection(\n    storage_directory=\"path/to/raw_data\",\n    db_schema=schema\n)\n\n# Create an atlas for processed data\nam = AtlasManager(\n    atlas_name=\"my_atlas\",\n    db_schema=schema,\n    storage_directory=\"path/to/atlas\"\n)\nam.create()\n</code></pre>"},{"location":"getting_started/quickstart/#4-process-your-data","title":"4. Process Your Data","text":""},{"location":"getting_started/quickstart/#using-python-api","title":"Using Python API","text":"<pre><code>from soma_curation.dataset.anndataset import AnnDataset\n\n# Create and standardize a dataset\ndataset = AnnDataset(\n    atlas_manager=am,\n    collection=collection\n)\ndataset.standardize()\n</code></pre>"},{"location":"getting_started/quickstart/#5-ingest-data-into-atlas","title":"5. Ingest Data into Atlas","text":"<p>After standardizing your data, you can access the AnnData object and ingest it into your atlas with a single function call from <code>tiledbsoma.io</code>:</p> <pre><code>import tiledbsoma\n\n# Access the AnnData object from the dataset and ingest it into the atlas\ntiledbsoma.io.from_anndata(\n    experiment_uri=str(am.experiment_path),\n    measurement_name=\"RNA\",\n    anndata=dataset.artifact\n)\n\nprint(\"Data successfully ingested into atlas!\")\n</code></pre>"},{"location":"getting_started/quickstart/#using-command-line-interface","title":"Using Command Line Interface","text":"<p>For large-scale data processing, use the multiprocessing ingestion script:</p> <pre><code>python -m soma_curation.scripts.multiprocessing_ingest \\\n    --processes 4 \\\n    --atlas-name my_atlas \\\n    --raw-storage-dir path/to/raw_data \\\n    --h5ad-storage-dir path/to/h5ads \\\n    --atlas-storage-dir path/to/atlas \\\n    --log-dir path/to/logs\n</code></pre> <p>Key command line options:</p> <ul> <li><code>--processes</code>: Number of worker processes (default: 4)</li> <li><code>--atlas-name</code>: Name of the atlas</li> <li><code>--raw-storage-dir</code>: Directory containing raw data</li> <li><code>--h5ad-storage-dir</code>: Directory for H5AD file storage</li> <li><code>--atlas-storage-dir</code>: Directory for atlas storage</li> <li><code>--log-dir</code>: Directory for logs</li> <li><code>--db-schema-fp</code>: Optional path to custom schema file</li> </ul>"},{"location":"getting_started/quickstart/#next-steps","title":"Next Steps","text":"<ul> <li>Learn more about Schema Definition</li> <li>Explore Data Organization</li> <li>Check out Advanced Usage for more complex scenarios</li> </ul>"},{"location":"getting_started/releases/","title":"Releases and Versioning","text":"<p>SOMA Curation follows Semantic Versioning with a \"v\" prefix.</p>"},{"location":"getting_started/releases/#release-types","title":"Release Types","text":"<ul> <li>Stable Releases: Format <code>v1.0.0</code></li> <li>Release Candidates: Format <code>v1.0.0-rc</code>, <code>v1.0.0-rc1</code>, etc.</li> </ul>"},{"location":"getting_started/releases/#installation","title":"Installation","text":""},{"location":"getting_started/releases/#stable-releases-pypi","title":"Stable Releases (PyPI)","text":"<pre><code>pip install soma-curation\n</code></pre>"},{"location":"getting_started/releases/#release-candidates-testpypi","title":"Release Candidates (TestPyPI)","text":"<pre><code>pip install --index-url https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple soma-curation\n</code></pre>"},{"location":"getting_started/releases/#documentation-versions","title":"Documentation Versions","text":"<ul> <li>latest: Most recent stable release</li> <li>next: Most recent release candidate</li> <li>dev: Latest changes from the main branch</li> <li>vX.Y: Major.minor version (e.g., <code>v1.0</code>)</li> <li>vX.Y.Z: Specific version (e.g., <code>v1.0.0</code>)</li> </ul>"},{"location":"usage/basics/","title":"Create an Atlas","text":"In\u00a0[\u00a0]: Copied! <pre>!pip install data_curation\n</pre> !pip install data_curation In\u00a0[\u00a0]: Copied! <pre>import soma_curation.sc_logging as lg\nfrom soma_curation.schema import get_schema\nfrom soma_curation.atlas.crud import AtlasManager\nfrom soma_curation.dataset.anndataset import AnnDataset\nfrom soma_curation.constants.constants import dummy_anndata\n\n# Set the log level to info\nlg.info()\n</pre> import soma_curation.sc_logging as lg from soma_curation.schema import get_schema from soma_curation.atlas.crud import AtlasManager from soma_curation.dataset.anndataset import AnnDataset from soma_curation.constants.constants import dummy_anndata  # Set the log level to info lg.info() In\u00a0[\u00a0]: Copied! <pre>db_schema = get_schema()\n</pre> db_schema = get_schema() In\u00a0[\u00a0]: Copied! <pre>am = AtlasManager(atlas_name=\"human\", globals_=db_schema, storage_directory=\"~/data_curation\")\nam.create()\n# am.delete() # to delete\n</pre> am = AtlasManager(atlas_name=\"human\", globals_=db_schema, storage_directory=\"~/data_curation\") am.create() # am.delete() # to delete In\u00a0[\u00a0]: Copied! <pre># Assuming that you fetch a cool dataset from somewhere\nanndata = dummy_anndata()\n</pre> # Assuming that you fetch a cool dataset from somewhere anndata = dummy_anndata() In\u00a0[\u00a0]: Copied! <pre># Create a Phenomic dataset using our schema, errors will pop up\n# if this dataset does not follow the schema specified in\n# db_schema.VALIDATION_SCHEMA\ndataset = AnnDataset(artifact=anndata, database_schema=db_schema)\n</pre> # Create a Phenomic dataset using our schema, errors will pop up # if this dataset does not follow the schema specified in # db_schema.VALIDATION_SCHEMA dataset = AnnDataset(artifact=anndata, database_schema=db_schema) In\u00a0[\u00a0]: Copied! <pre># Standardize the columns\n# This will run a general standardization pipeline, which involves:\n# (a) Fixing the gene names\n# (b) Embedding and predicting cell types\n# (c) Normalizing the arrays\ndataset.standardize()\n</pre> # Standardize the columns # This will run a general standardization pipeline, which involves: # (a) Fixing the gene names # (b) Embedding and predicting cell types # (c) Normalizing the arrays dataset.standardize()"},{"location":"usage/basics/#create-an-atlas","title":"Create an Atlas\u00b6","text":"<p>This notebook demonstrates how to create a Phenomic SOMA atlas with a predefined schema, create a <code>Dataset</code> that adheres to that schema, and append information to it.</p>"},{"location":"usage/data_organization/","title":"Data Organization","text":"<p>SOMA Curation expects a specific directory structure for your raw data. Following this structure ensures that your data can be properly ingested and processed.</p>"},{"location":"usage/data_organization/#directory-structure","title":"Directory Structure","text":"<pre><code>raw_data/\n\u251c\u2500\u2500 study_1/\n\u2502   \u251c\u2500\u2500 mtx/                 # Matrix files\n\u2502   \u2502   \u251c\u2500\u2500 sample_1/        # Each sample has its own directory\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 matrix.mtx.gz\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 barcodes.tsv.gz\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 features.tsv.gz\n\u2502   \u2502   \u2514\u2500\u2500 sample_2/\n\u2502   \u2502       \u2514\u2500\u2500 ...\n\u2502   \u251c\u2500\u2500 cell_metadata/       # Cell-level metadata\n\u2502   \u2502   \u2514\u2500\u2500 study_1.tsv.gz   # Named after the study\n\u2502   \u2514\u2500\u2500 sample_metadata/     # Sample-level metadata\n\u2502       \u2514\u2500\u2500 study_1.tsv.gz   # Named after the study\n\u2514\u2500\u2500 study_2/\n    \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"usage/data_organization/#file-formats","title":"File Formats","text":""},{"location":"usage/data_organization/#matrix-files","title":"Matrix Files","text":"<p>Matrix files use the Matrix Market format (<code>.mtx.gz</code>), which efficiently stores sparse matrices. Each sample directory must contain:</p> <ul> <li><code>matrix.mtx.gz</code>: The gene expression matrix (genes \u00d7 cells)</li> <li><code>barcodes.tsv.gz</code>: Cell barcodes</li> <li><code>features.tsv.gz</code>: Gene features</li> </ul>"},{"location":"usage/data_organization/#metadata-files","title":"Metadata Files","text":"<p>Metadata files use tab-separated values (<code>.tsv.gz</code>):</p> <ul> <li><code>sample_metadata/&lt;study_name&gt;.tsv.gz</code>: Contains sample-level information</li> <li><code>cell_metadata/&lt;study_name&gt;.tsv.gz</code>: Contains cell-level information</li> </ul>"},{"location":"usage/data_organization/#validation","title":"Validation","text":"<p>SOMA Curation performs several validations when loading data:</p> <ul> <li>Checks for directory structure correctness</li> <li>Validates file formats and content</li> <li>Ensures metadata columns match the schema</li> <li>Verifies no duplicate sample names across studies</li> </ul>"},{"location":"usage/data_organization/#best-practices","title":"Best Practices","text":"<ol> <li>Consistent Naming: Use consistent naming conventions for studies and samples</li> <li>Compression: Always compress files (<code>.gz</code>) to save space</li> <li>Metadata Organization: Keep metadata well-organized and consistent</li> <li>Schema First: Define your schema before organizing data</li> <li>Sample Uniqueness: Ensure sample names are unique across all studies</li> </ol>"}]}